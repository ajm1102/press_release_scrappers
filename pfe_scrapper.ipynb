{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71348155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def changes_from_press(stock_data, press_date, period):\n",
    "    next_day = timedelta(days=1)\n",
    "    time_after_release = timedelta(days=period)\n",
    "    \n",
    "\n",
    "    next_trading_day = press_date\n",
    "    \n",
    "    # try to obtain share price at open on press release date\n",
    "    day_1_price = stock_data[stock_data['Date'] == press_date]['Open'].values\n",
    "\n",
    "\n",
    "    # increase the date till the first available open price is found\n",
    "    num_days = 1\n",
    "    while not day_1_price:\n",
    "        if num_days > 30:\n",
    "            return None\n",
    "        \n",
    "        next_trading_day = next_trading_day + next_day\n",
    "\n",
    "        day_1_price = stock_data[stock_data['Date'] == (next_trading_day)]['Open'].values\n",
    "        num_days = num_days + 1\n",
    "\n",
    "    # get next day if available\n",
    "    next_trading_day = next_trading_day + time_after_release\n",
    "    day_2_price = stock_data[stock_data['Date'] == (next_trading_day)]['Close'].values\n",
    "\n",
    "    # increase the date till the second available close price is found\n",
    "    num_days = 1\n",
    "    while not day_2_price:\n",
    "        if num_days > 30: \n",
    "            return None\n",
    "        \n",
    "        next_trading_day = next_trading_day + next_day\n",
    "\n",
    "        day_2_price = stock_data[stock_data['Date'] == (next_trading_day + next_day)]['Close'].values\n",
    "        num_days = num_days + 1\n",
    "    \n",
    "    # calcualte percent difference between share prices\n",
    "    pct_change = ((day_2_price - day_1_price) / day_2_price)*100\n",
    "    pct_change = pct_change[0]\n",
    "    return pct_change\n",
    "\n",
    "def get_df(ticker):\n",
    "    \n",
    "    stock_data = yf.Ticker(ticker)\n",
    "\n",
    "    # get historical market data\n",
    "    stock_hist = stock_data.history(period=\"max\")\n",
    "\n",
    "    stock_hist.reset_index(inplace=True)\n",
    "\n",
    "    stock_hist['Date'] = pd.to_datetime(stock_hist['Date']).dt.date\n",
    "\n",
    "    stock_hist['Pct_Close'] = stock_hist['Close'].pct_change()*100\n",
    "\n",
    "    return stock_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec18c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AidanLaptop\\AppData\\Local\\Temp\\ipykernel_7260\\2593293535.py:38: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  while not day_2_price:\n",
      "C:\\Users\\AidanLaptop\\AppData\\Local\\Temp\\ipykernel_7260\\2593293535.py:23: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  while not day_1_price:\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "ticker = 'pfe'\n",
    "\n",
    "stock_hist = get_df(ticker)\n",
    "\n",
    "page_num = 0\n",
    "# create break\n",
    "while True:    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"}\n",
    "    \n",
    "    s = requests.Session()\n",
    "    html = requests.get(f'https://www.pfizer.com/news/press-releases?items_per_page=48&page={page_num}', headers=headers)\n",
    "    \n",
    "\n",
    "    soup = BeautifulSoup(html.content) \n",
    "\n",
    "    articles = soup.find_all('li',attrs={'class':'grid-x'})\n",
    "    \n",
    "    if not articles:\n",
    "        break\n",
    "    \n",
    "    for article in articles:\n",
    "        # remove starting and trailing whitespaces\n",
    "        date = article.find('helix-core-content', attrs={'slot':'date'}).text.lstrip().rstrip()\n",
    "        title = article.find('helix-core-heading', attrs={'variant':'h4'}).text.lstrip().rstrip()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        date = datetime.strptime(date, '%m.%d.%Y').date()\n",
    "        pct_change = changes_from_press(stock_hist, date, 1)\n",
    "        \n",
    "        data.append([date, title, pct_change])\n",
    "    page_num = page_num + 1\n",
    "    \n",
    "    \n",
    "data = pd.DataFrame(data, columns=['date', 'press title', '1d change'])\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "dates_str = [date.strftime(\"%m/%d/%Y\") for date in data['date'].tolist()]\n",
    "result = data.to_json(orient=\"values\", index=True)\n",
    "\n",
    "\n",
    "dict_data = {\n",
    "    'ticker': ticker,\n",
    "    'data': json.loads(result),\n",
    "    },\n",
    "\n",
    "\n",
    "with open(f'./data/{ticker}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dict_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9c167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
